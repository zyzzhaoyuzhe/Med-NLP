{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zyzzhaoyuzhe/virtualenvs/nlp3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import utils\n",
    "from collections import defaultdict, OrderedDict\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack, vstack\n",
    "import tensorflow as tf\n",
    "from nn_models import TextCNN, TextCNN_field_aware, TextRNN, TextRNN_field_aware, TextRNN_attention\n",
    "import data_helpers\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERED_NAMES = [u'study',\n",
    "                 u'history',\n",
    "                 u'comparison',\n",
    "                 u'technique',\n",
    "                 u'findings',\n",
    "                 u'impression', \n",
    "                 u'signed by',\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "df_processed = pickle.load(open('Data/DataFrame_processed.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1220, 5)\n",
      "(307, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    1172\n",
       " 1     355\n",
       "Name: Past, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TO_PREDICT = 'Past'\n",
    "FIELDS = [\n",
    "    'history',\n",
    "    'findings',\n",
    "    'comparison',\n",
    "    'impression',\n",
    "#     'Grade',\n",
    "#     'Present',\n",
    "#     'Past'\n",
    "]\n",
    "\n",
    "# df_filtered = df_processed[~df_processed[TO_PREDICT].isnull() & (df_processed[TO_PREDICT] != 0)].sample(frac=1, random_state=1)\n",
    "df_filtered = df_processed[~df_processed[TO_PREDICT].isnull()].sample(frac=1, random_state=1)\n",
    "df_filtered = df_filtered[[TO_PREDICT] + FIELDS]\n",
    "\n",
    "df_train = df_filtered.iloc[:1220]\n",
    "y_train = np.array(df_train[TO_PREDICT].astype(int))\n",
    "enc = LabelEncoder()\n",
    "enc.fit(y_train)\n",
    "y_train = enc.transform(y_train)\n",
    "\n",
    "df_test = df_filtered.iloc[1220:]\n",
    "y_test = np.array(df_test[TO_PREDICT].astype(int))\n",
    "y_test = enc.transform(y_test)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_filtered[TO_PREDICT].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Past', 'history', 'findings', 'comparison', 'impression'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = [100,\n",
    "          125,\n",
    "          50,\n",
    "          100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zyzzhaoyuzhe/virtualenvs/nlp3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_text = utils.Dataframe_Proc.df2text(df_train, df_train.columns[1:])\n",
    "word2idx, idx2word = utils.Text_Proc.ngram_vocab_processor(x_train_text, ngram=1, min_count=2)\n",
    "x_train = np.array(utils.Text_Proc.encode_texts(x_train_text, word2idx, maxlen=sum(maxlen)))\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, None])\n",
    "\n",
    "x_dev_text = utils.Dataframe_Proc.df2text(df_test, df_test.columns[1:])\n",
    "x_dev = np.array(utils.Text_Proc.encode_texts(x_dev_text, word2idx, maxlen=x_train.shape[1]))\n",
    "\n",
    "y_dev = enc.transform(y_test[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1220, 375)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x136bda3c8>\n",
      "BATCH_SIZE=<absl.flags._flag.Flag object at 0x12d8d9f98>\n",
      "CHECKPOINT_EVERY=<absl.flags._flag.Flag object at 0x12d8d7a58>\n",
      "DROPOUT_KEEP_PROB=<absl.flags._flag.Flag object at 0x136bdd160>\n",
      "EMBEDDING_DIM=<absl.flags._flag.Flag object at 0x136bddda0>\n",
      "EVALUATE_EVERY=<absl.flags._flag.Flag object at 0x12d8d74e0>\n",
      "F=<absl.flags._flag.Flag object at 0x12f18e9e8>\n",
      "FILTER_SIZES=<absl.flags._flag.Flag object at 0x136bddc88>\n",
      "HIDDEN_SIZE=<absl.flags._flag.Flag object at 0x12e092a90>\n",
      "L2_REG_LAMBDA=<absl.flags._flag.Flag object at 0x136bdd9e8>\n",
      "LEARNING_RATE=<absl.flags._flag.Flag object at 0x12d8d9828>\n",
      "LOG_DEVICE_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x119d9bef0>\n",
      "LOG_EVERY=<absl.flags._flag.Flag object at 0x136bdad68>\n",
      "NUM_CHECKPOINTS=<absl.flags._flag.Flag object at 0x12d8d7a90>\n",
      "NUM_EPOCHS=<absl.flags._flag.Flag object at 0x12d8d9080>\n",
      "NUM_FILTERS=<absl.flags._flag.Flag object at 0x12e0922b0>\n",
      "NUM_LAYERS=<absl.flags._flag.Flag object at 0x12e092ac8>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear flags\n",
    "if FLAGS._flags():\n",
    "    for key in [key for key in FLAGS._flags().keys()]:\n",
    "        FLAGS.__delattr__(key)\n",
    "\n",
    "# Both CNN and RNN\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 64, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.1, \"L2 regularization lambda (default: 0.0)\")\n",
    "\n",
    "# CNN parameter\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"3,4\", \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 128)\")\n",
    "\n",
    "# RNN parameter\n",
    "tf.flags.DEFINE_integer('hidden_size', 64, 'Hidden size of LSTM')\n",
    "tf.flags.DEFINE_integer('num_layers', 1, 'Number of LSTM layers')\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\", 1e-3, \"learning rate\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 100, \"Number of training epochs (default: 200)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 100, \"Save model after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")\n",
    "tf.flags.DEFINE_integer(\"log_every\", 10, \"Logs model on dev set after this many steps (default: 100)\")\n",
    "\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "# Fix Bugs \n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "# FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.\n",
      "Writing to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193\n",
      "\n",
      "2019-03-13T23:13:15.632740: step 10, loss 2.12545, acc 0.6875\n",
      "2019-03-13T23:13:17.715807: step 20, loss 2.1414, acc 0.75\n",
      "2019-03-13T23:13:19.749547: step 30, loss 1.20046, acc 0.703125\n",
      "2019-03-13T23:13:21.904154: step 40, loss 1.47341, acc 0.5\n",
      "2019-03-13T23:13:24.154007: step 50, loss 1.79901, acc 0.640625\n",
      "2019-03-13T23:13:25.915468: step 60, loss 0.725859, acc 0.75\n",
      "2019-03-13T23:13:27.795435: step 70, loss 0.961079, acc 0.703125\n",
      "2019-03-13T23:13:29.519168: step 80, loss 0.639446, acc 0.75\n",
      "2019-03-13T23:13:31.452836: step 90, loss 1.13969, acc 0.78125\n",
      "2019-03-13T23:13:33.184744: step 100, loss 0.370727, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:13:33.468295: step 100, loss 0.531659, acc 0.840391\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-100\n",
      "\n",
      "2019-03-13T23:13:35.480694: step 110, loss 1.05689, acc 0.734375\n",
      "2019-03-13T23:13:37.226730: step 120, loss 2.39147, acc 0.5\n",
      "2019-03-13T23:13:39.173592: step 130, loss 1.19633, acc 0.671875\n",
      "2019-03-13T23:13:40.941221: step 140, loss 0.606984, acc 0.75\n",
      "2019-03-13T23:13:42.883183: step 150, loss 0.717635, acc 0.78125\n",
      "2019-03-13T23:13:44.693603: step 160, loss 0.87193, acc 0.75\n",
      "2019-03-13T23:13:46.616886: step 170, loss 0.715929, acc 0.859375\n",
      "2019-03-13T23:13:48.374916: step 180, loss 0.161275, acc 1\n",
      "2019-03-13T23:13:50.358383: step 190, loss 0.695203, acc 0.8125\n",
      "2019-03-13T23:13:52.122476: step 200, loss 0.372137, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:13:52.390781: step 200, loss 0.470571, acc 0.876221\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-200\n",
      "\n",
      "2019-03-13T23:13:54.407105: step 210, loss 0.560575, acc 0.84375\n",
      "2019-03-13T23:13:56.155722: step 220, loss 0.197143, acc 1\n",
      "2019-03-13T23:13:58.139709: step 230, loss 0.323017, acc 0.953125\n",
      "2019-03-13T23:14:00.022709: step 240, loss 0.213582, acc 1\n",
      "2019-03-13T23:14:02.146434: step 250, loss 0.621349, acc 0.8125\n",
      "2019-03-13T23:14:04.022417: step 260, loss 0.163264, acc 1\n",
      "2019-03-13T23:14:06.059916: step 270, loss 0.418133, acc 0.921875\n",
      "2019-03-13T23:14:07.912024: step 280, loss 0.396115, acc 1\n",
      "2019-03-13T23:14:10.053448: step 290, loss 0.419815, acc 0.84375\n",
      "2019-03-13T23:14:11.841823: step 300, loss 0.474084, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:14:12.105009: step 300, loss 0.478348, acc 0.872964\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-300\n",
      "\n",
      "2019-03-13T23:14:14.170401: step 310, loss 0.531493, acc 0.859375\n",
      "2019-03-13T23:14:15.977899: step 320, loss 0.289353, acc 1\n",
      "2019-03-13T23:14:17.897982: step 330, loss 0.449266, acc 0.859375\n",
      "2019-03-13T23:14:19.702314: step 340, loss 0.134132, acc 1\n",
      "2019-03-13T23:14:21.798792: step 350, loss 0.597275, acc 0.859375\n",
      "2019-03-13T23:14:23.798560: step 360, loss 0.380337, acc 1\n",
      "2019-03-13T23:14:26.109060: step 370, loss 0.38471, acc 0.84375\n",
      "2019-03-13T23:14:28.280226: step 380, loss 0.482499, acc 0.75\n",
      "2019-03-13T23:14:30.303921: step 390, loss 0.296633, acc 0.9375\n",
      "2019-03-13T23:14:32.082384: step 400, loss 0.185124, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:14:32.347422: step 400, loss 0.405999, acc 0.892508\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-400\n",
      "\n",
      "2019-03-13T23:14:34.363768: step 410, loss 0.446188, acc 0.921875\n",
      "2019-03-13T23:14:36.157338: step 420, loss 1.21085, acc 0.75\n",
      "2019-03-13T23:14:38.118570: step 430, loss 0.467205, acc 0.859375\n",
      "2019-03-13T23:14:40.017155: step 440, loss 1.55648, acc 0.75\n",
      "2019-03-13T23:14:42.187176: step 450, loss 0.726433, acc 0.796875\n",
      "2019-03-13T23:14:44.163370: step 460, loss 0.597948, acc 0.75\n",
      "2019-03-13T23:14:46.441587: step 470, loss 0.327779, acc 0.921875\n",
      "2019-03-13T23:14:48.498089: step 480, loss 0.299631, acc 0.75\n",
      "2019-03-13T23:14:50.717515: step 490, loss 0.251853, acc 0.9375\n",
      "2019-03-13T23:14:52.560862: step 500, loss 1.00085, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:14:52.843444: step 500, loss 0.376195, acc 0.889251\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-500\n",
      "\n",
      "2019-03-13T23:14:54.937085: step 510, loss 0.248295, acc 0.9375\n",
      "2019-03-13T23:14:56.817122: step 520, loss 0.117516, acc 1\n",
      "2019-03-13T23:14:59.090480: step 530, loss 0.358135, acc 0.90625\n",
      "2019-03-13T23:15:01.183830: step 540, loss 0.13376, acc 1\n",
      "2019-03-13T23:15:03.394858: step 550, loss 0.425496, acc 0.875\n",
      "2019-03-13T23:15:05.205729: step 560, loss 1.01003, acc 0.75\n",
      "2019-03-13T23:15:07.195881: step 570, loss 0.225114, acc 0.96875\n",
      "2019-03-13T23:15:09.091058: step 580, loss 0.14093, acc 1\n",
      "2019-03-13T23:15:11.308088: step 590, loss 0.400861, acc 0.90625\n",
      "2019-03-13T23:15:14.209097: step 600, loss 0.120134, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:15:14.833078: step 600, loss 0.360093, acc 0.892508\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-600\n",
      "\n",
      "2019-03-13T23:15:17.012779: step 610, loss 0.285833, acc 0.90625\n",
      "2019-03-13T23:15:18.950819: step 620, loss 0.114599, acc 1\n",
      "2019-03-13T23:15:21.197873: step 630, loss 0.179827, acc 0.984375\n",
      "2019-03-13T23:15:23.194600: step 640, loss 0.190024, acc 1\n",
      "2019-03-13T23:15:25.654969: step 650, loss 0.175272, acc 0.96875\n",
      "2019-03-13T23:15:27.535467: step 660, loss 0.22059, acc 1\n",
      "2019-03-13T23:15:29.785709: step 670, loss 0.347534, acc 0.953125\n",
      "2019-03-13T23:15:31.661111: step 680, loss 0.446568, acc 0.75\n",
      "2019-03-13T23:15:33.907875: step 690, loss 0.215051, acc 0.921875\n",
      "2019-03-13T23:15:35.813910: step 700, loss 0.17427, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:15:36.145537: step 700, loss 0.345256, acc 0.889251\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-700\n",
      "\n",
      "2019-03-13T23:15:38.654654: step 710, loss 0.167133, acc 0.984375\n",
      "2019-03-13T23:15:40.483255: step 720, loss 0.165225, acc 1\n",
      "2019-03-13T23:15:42.435133: step 730, loss 0.300546, acc 0.921875\n",
      "2019-03-13T23:15:44.286043: step 740, loss 0.309739, acc 0.75\n",
      "2019-03-13T23:15:46.289403: step 750, loss 0.249606, acc 0.953125\n",
      "2019-03-13T23:15:48.158970: step 760, loss 0.146956, acc 1\n",
      "2019-03-13T23:15:50.202127: step 770, loss 0.187187, acc 0.953125\n",
      "2019-03-13T23:15:52.025771: step 780, loss 0.102607, acc 1\n",
      "2019-03-13T23:15:54.055699: step 790, loss 0.193127, acc 0.984375\n",
      "2019-03-13T23:15:55.882980: step 800, loss 0.31439, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:15:56.235209: step 800, loss 0.336022, acc 0.895765\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-800\n",
      "\n",
      "2019-03-13T23:15:58.352395: step 810, loss 0.310566, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-13T23:16:00.196600: step 820, loss 0.902088, acc 0.75\n",
      "2019-03-13T23:16:02.255465: step 830, loss 0.198542, acc 0.921875\n",
      "2019-03-13T23:16:04.392791: step 840, loss 0.176717, acc 1\n",
      "2019-03-13T23:16:06.675415: step 850, loss 0.301644, acc 0.921875\n",
      "2019-03-13T23:16:08.624880: step 860, loss 0.105039, acc 1\n",
      "2019-03-13T23:16:11.167899: step 870, loss 0.216011, acc 0.953125\n",
      "2019-03-13T23:16:13.411588: step 880, loss 0.229954, acc 1\n",
      "2019-03-13T23:16:15.958366: step 890, loss 0.280582, acc 0.890625\n",
      "2019-03-13T23:16:17.863827: step 900, loss 0.0742189, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-03-13T23:16:18.169473: step 900, loss 0.324054, acc 0.899023\n",
      "\n",
      "Saved model checkpoint to /Users/zyzzhaoyuzhe/Documents/Med-NLP/runs/CNN_64_128_1552533193/checkpoints/model-900\n",
      "\n",
      "2019-03-13T23:16:20.284482: step 910, loss 0.247719, acc 0.953125\n",
      "2019-03-13T23:16:22.107352: step 920, loss 0.0954444, acc 1\n",
      "2019-03-13T23:16:24.169602: step 930, loss 0.306952, acc 0.921875\n",
      "2019-03-13T23:16:26.002276: step 940, loss 0.597108, acc 0.75\n",
      "2019-03-13T23:16:27.964639: step 950, loss 0.134849, acc 0.984375\n",
      "2019-03-13T23:16:29.756201: step 960, loss 0.591792, acc 0.75\n",
      "2019-03-13T23:16:31.747658: step 970, loss 0.227271, acc 0.921875\n",
      "2019-03-13T23:16:33.539996: step 980, loss 0.097568, acc 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        \n",
    "        model = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=y_train.shape[1],\n",
    "            vocab_size=len(word2idx),\n",
    "            embedding_size=FLAGS.embedding_dim,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "#         model = TextCNN_field_aware(sequence_lengths=maxlen,\n",
    "#                                     num_classes=y_train.shape[1],\n",
    "#                                     vocab_size=len(word2idx),\n",
    "#                                     embedding_size=FLAGS.embedding_dim,\n",
    "#                                     filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "#                                     num_filters=FLAGS.num_filters,\n",
    "#                                     l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "#         model = TextRNN(sequence_length=sum(maxlen),\n",
    "#                         num_classes=y_train.shape[1],\n",
    "#                         vocab_size=len(word2idx),\n",
    "#                         embedding_size=FLAGS.embedding_dim,\n",
    "#                         hidden_size=FLAGS.hidden_size,\n",
    "#                         num_layers=FLAGS.num_layers,\n",
    "#                         l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "#         model = TextRNN_field_aware(sequence_lengths=maxlen,\n",
    "#                                     num_classes=y_train.shape[1],\n",
    "#                                     vocab_size=len(word2idx),\n",
    "#                                     embedding_size=FLAGS.embedding_dim,\n",
    "#                                     hidden_size=FLAGS.hidden_size,\n",
    "#                                     num_layers=FLAGS.num_layers,\n",
    "#                                     l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "#         model = TextRNN_attention(sequence_length=sum(maxlen),\n",
    "#                         num_classes=y_train.shape[1],\n",
    "#                         vocab_size=len(word2idx),\n",
    "#                         embedding_size=FLAGS.embedding_dim,\n",
    "#                         hidden_size=FLAGS.hidden_size,\n",
    "#                         num_layers=FLAGS.num_layers,\n",
    "#                         l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "\n",
    "        # Define Training procedure\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "        optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(model.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "        # Keep track of gradient values and sparsity (optional)\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "        # Output directory for models and summaries\n",
    "        timestamp = str(int(time.time()))\n",
    "\n",
    "        if 'CNN' in model.__class__.__name__:\n",
    "            name = \"CNN_{}_{}_\".format(FLAGS.embedding_dim, FLAGS.num_filters)\n",
    "        elif 'RNN' in model.__class__.__name__:\n",
    "            name = \"RNN_{}_{}_{}_\".format(FLAGS.embedding_dim, FLAGS.hidden_size, FLAGS.num_layers)\n",
    "\n",
    "\n",
    "        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", name + timestamp))\n",
    "        print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "        # Summaries for loss and accuracy\n",
    "        loss_summary = tf.summary.scalar(\"loss\", model.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", model.accuracy)\n",
    "\n",
    "        # Train Summaries\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        # Dev summaries\n",
    "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        # vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "                model.input_x: x_batch,\n",
    "                model.input_y: y_batch,\n",
    "                model.dropout_keep_prob: FLAGS.dropout_keep_prob,\n",
    "                model.batch_size: len(x_batch)\n",
    "            }\n",
    "\n",
    "            _, step, summaries, loss, accuracy = sess.run(\n",
    "                [train_op, global_step, train_summary_op, model.loss, model.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            if step % FLAGS.log_every == 0:\n",
    "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "                model.input_x: x_batch,\n",
    "                model.input_y: y_batch,\n",
    "                model.dropout_keep_prob: 1.0,\n",
    "                model.batch_size: len(x_batch)\n",
    "            }\n",
    "\n",
    "            step, summaries, loss, accuracy = sess.run(\n",
    "                [global_step, dev_summary_op, model.loss, model.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "\n",
    "        # Generate batches\n",
    "        batches = data_helpers.batch_iter(\n",
    "            list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "        # Training loop. For each batch...\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            if current_step % FLAGS.evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                print(\"\")\n",
    "            if current_step % FLAGS.checkpoint_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "\n",
    "        #\n",
    "        feed_dict = {\n",
    "            model.input_x: x_dev,\n",
    "            model.input_y: y_dev,\n",
    "            model.dropout_keep_prob: 1.0,\n",
    "            model.batch_size: len(x_dev)\n",
    "        }\n",
    "        y_dev_pred = sess.run([model.predictions], feed_dict=feed_dict)\n",
    "        y_dev_prob = sess.run([tf.math.exp(model.logits)], feed_dict=feed_dict)\n",
    "#         y_dev_pred, alpha = sess.run([model.predictions, model.alpha], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR Curve\n",
    "pr_curves = []  # reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x136be1a20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PR Curve\n",
    "pr_curves.append(precision_recall_curve(y_test, y_dev_prob[0][:, 1]))\n",
    "for pr_curve in pr_curves:\n",
    "    plt.plot(pr_curve[1], pr_curve[0])\n",
    "plt.legend(range(len(pr_curves)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "rocs = []  # reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13650d748>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curve\n",
    "rocs.append(roc_curve(y_test, y_dev_prob[0][:, 1]))\n",
    "for roc in rocs:\n",
    "    plt.plot(roc[0], roc[1])\n",
    "plt.legend(range(len(rocs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zyzzhaoyuzhe/Documents/Med-NLP/utils.py:507: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = CM.iloc[1, 1] / CM.iloc[:, 1].sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sensitivity    0.000000\n",
       "specificity    1.000000\n",
       "precision           NaN\n",
       "NPV            0.794788\n",
       "accuracy       0.794788\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.my_classification_report(y_test, y_dev_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"TextRNN_field_aware\"\n",
    "output = output_report(y_test, y_dev_pred[0])\n",
    "output.to_csv(\"CI/\" + model +'.csv', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
