{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from collections import defaultdict, OrderedDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "velo_fields = {\n",
    "    'cca': ['common carotid', 'cca'],\n",
    "    'bulb': ['carotid bulb'],\n",
    "    'eca': ['external carotid'],\n",
    "    'ica': ['internal carotid', 'ica']\n",
    "}\n",
    "prefix = {\n",
    "    'p': ['proximal', 'prox'],\n",
    "    'd': ['distal', 'dist'],\n",
    "    'm': ['middle', 'mid'],\n",
    "}\n",
    "fuzzyName = {\n",
    "    'study': ['study', 'examination'],\n",
    "    'findings': ['findings'],\n",
    "    'impression': ['impression'],\n",
    "    'history': ['history', 'indication'],\n",
    "    'comparison': ['comparison'],\n",
    "    'technique': ['technique'],\n",
    "    'signed by': ['signed by'],\n",
    "}\n",
    "orderField = [u'study',\n",
    "              u'history',\n",
    "              u'comparison',\n",
    "              u'technique',\n",
    "              u'findings',\n",
    "              u'impression', \n",
    "              u'signed by',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'Data/upto1526.xlsx'\n",
    "df_raw = pd.read_excel(open(filename, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get data frame\n",
    "ps = Parser(fuzzyName)\n",
    "ps.parser(df_raw)\n",
    "df = ps.df\n",
    "for idx, row in df['findings'].iteritems():\n",
    "    try:\n",
    "        text, velos = parse_findings(row)\n",
    "        df.set_value(idx, 'findings', text)\n",
    "        for n, v in velos:\n",
    "            df.set_value(idx, n, v)\n",
    "    except:\n",
    "        pass\n",
    "discardField = ['Report Text']\n",
    "foo = [item for item in df.columns.tolist() if item not in orderField+discardField]\n",
    "foo.sort()\n",
    "CORE_COL = orderField + foo\n",
    "df = df[CORE_COL]\n",
    "df = pd.concat([df_raw[['Past', 'Present']], df[CORE_COL]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = null2empty(df, 'history' 'impression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to documents\n",
    "#df[col].to_excel('reports(07192017).xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use findings and impression to predict present and pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1525, 47)\n"
     ]
    }
   ],
   "source": [
    "df = null2empty(df, ['history', 'impression', 'comparison'])\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for PAST\n",
    "fields = ['history', 'impression', 'findings', 'comparison']\n",
    "foo = df[~df['Past'].isnull() & df['Past'] != 0].sample(frac=1)\n",
    "df_train = df.iloc[:900]\n",
    "y_train = np.array(df_train['Past'].astype(int))\n",
    "df_test = df.iloc[900:]\n",
    "y_test = np.array(df_test['Past'].astype(int))\n",
    "obj = Df2TFIDF()\n",
    "obj.fit(df_train, fields, ngram=1, min_count=2)\n",
    "output_train = obj.transform(df_train, fields)\n",
    "output_test = obj.transform(df_test, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1880)\n(625, 1880)\n"
     ]
    }
   ],
   "source": [
    "# concatenate sparse matrices of all fields\n",
    "from scipy.sparse import hstack\n",
    "x_train = hstack([foo['bow_tfidf'] for foo in output_train.itervalues()])\n",
    "# TODO (xiao)\n",
    "x_test = hstack([foo['bow_tfidf'] for foo in output_test.itervalues()])\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2text' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e267089cc794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Present'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Present'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Present'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtext_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Present'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Present'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmsk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Present'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2text' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#for PRESENT\n",
    "fields = ['history','impression','findings', 'comparison']\n",
    "msk1 = np.random.rand(len(df[~df['Present'].isnull() & df['Present'] != 0])) < 0.7\n",
    "df_train = df[~df['Present'].isnull() & df['Present'] != 0][msk1]\n",
    "y_train = np.array(df_train['Present'].astype(int))\n",
    "text_train = df2text(df_train, fields=fields)\n",
    "df_test = df[~df['Present'].isnull() & df['Present'] != 0][~msk1]\n",
    "y_test = np.array(df_test['Present'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76412721611d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionary = defaultdict(int)\n",
    "#for text in x_train:\n",
    "#    for word in text.split():\n",
    "#        dictionary[word] += 1\n",
    "#len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import operator\n",
    "#foo = sorted(dictionary.items(), key=operator.itemgetter(1), reverse=True)\n",
    "#word2idx = {}\n",
    "#idx2word = {}\n",
    "#for idx, item in enumerate(foo):\n",
    "#    word2idx[item[0]] = idx\n",
    "#    idx2word[idx] = item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2idx.keys()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = text2data(df2text(df_train, fields=fields), word2idx)\n",
    "#data_test = text2data(df2text(df_test, fields=fields), word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transform = TfidfTransformer()\n",
    "output_train = transform.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# svm\n",
    "#clf = LinearSVC()\n",
    "#clf = SVC()\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955555555556\n0.9232\n"
     ]
    }
   ],
   "source": [
    "print clf.score(x_train, y_train)\n",
    "print clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734\n",
      "95\n",
      "191\n",
      "4\n",
      "240\n",
      "8\n",
      "109\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(data_train)\n",
    "y_test_pred = clf.predict(data_test)\n",
    "CM_train = confusion_matrix(y_train, y_train_pred)\n",
    "CM_test = confusion_matrix(y_test, y_test_pred)\n",
    "print CM_train[0][0] #TN\n",
    "print CM_train[1][0] #FN\n",
    "print CM_train[1][1] #TP\n",
    "print CM_train[0][1] #FP\n",
    "\n",
    "print CM_test[0][0] #TN\n",
    "print CM_test[1][0] #FN\n",
    "print CM_test[1][1] #TP\n",
    "print CM_test[0][1] #FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = np.asarray((data_train[:, 0] > 0).todense()) * 2 - 1\n",
    "sum(y_hat.squeeze() - np.array(y_train) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = np.asarray((data_test[:,0] > 0).todense()) * 2 - 1\n",
    "sum(y_hat.squeeze() - np.array(y_test) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}